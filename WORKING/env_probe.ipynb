{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "import gymnasium as gym\n",
                "import numpy as np\n",
                "import sinergym\n",
                "from sinergym.utils.common import get_ids\n",
                "from sinergym.utils.wrappers import (LoggerWrapper, NormalizeAction,\n",
                "                                     NormalizeObservation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['Eplus-demo-v1', 'Eplus-smalldatacenter-hot-continuous-v1', 'Eplus-smalldatacenter-hot-continuous-stochastic-v1', 'Eplus-smalldatacenter-mixed-continuous-v1', 'Eplus-smalldatacenter-mixed-continuous-stochastic-v1', 'Eplus-smalldatacenter-cool-continuous-v1', 'Eplus-smalldatacenter-cool-continuous-stochastic-v1', 'Eplus-datacenter-hot-continuous-v1', 'Eplus-datacenter-hot-discrete-v1', 'Eplus-datacenter-hot-continuous-stochastic-v1', 'Eplus-datacenter-hot-discrete-stochastic-v1', 'Eplus-datacenter-mixed-continuous-v1', 'Eplus-datacenter-mixed-discrete-v1', 'Eplus-datacenter-mixed-continuous-stochastic-v1', 'Eplus-datacenter-mixed-discrete-stochastic-v1', 'Eplus-datacenter-cool-continuous-v1', 'Eplus-datacenter-cool-discrete-v1', 'Eplus-datacenter-cool-continuous-stochastic-v1', 'Eplus-datacenter-cool-discrete-stochastic-v1', 'Eplus-5zone-hot-continuous-v1', 'Eplus-5zone-hot-discrete-v1', 'Eplus-5zone-hot-continuous-stochastic-v1', 'Eplus-5zone-hot-discrete-stochastic-v1', 'Eplus-5zone-mixed-continuous-v1', 'Eplus-5zone-mixed-discrete-v1', 'Eplus-5zone-mixed-continuous-stochastic-v1', 'Eplus-5zone-mixed-discrete-stochastic-v1', 'Eplus-5zone-cool-continuous-v1', 'Eplus-5zone-cool-discrete-v1', 'Eplus-5zone-cool-continuous-stochastic-v1', 'Eplus-5zone-cool-discrete-stochastic-v1', 'Eplus-simple_office-hot-continuous-v1', 'Eplus-simple_office-hot-discrete-v1', 'Eplus-simple_office-hot-continuous-stochastic-v1', 'Eplus-simple_office-hot-discrete-stochastic-v1', 'Eplus-simple_office-mixed-continuous-v1', 'Eplus-simple_office-mixed-discrete-v1', 'Eplus-simple_office-mixed-continuous-stochastic-v1', 'Eplus-simple_office-mixed-discrete-stochastic-v1', 'Eplus-simple_office-cool-continuous-v1', 'Eplus-simple_office-cool-discrete-v1', 'Eplus-simple_office-cool-continuous-stochastic-v1', 'Eplus-simple_office-cool-discrete-stochastic-v1', 'Eplus-office-hot-continuous-v1', 'Eplus-office-hot-discrete-v1', 'Eplus-office-hot-continuous-stochastic-v1', 'Eplus-office-hot-discrete-stochastic-v1', 'Eplus-office-mixed-continuous-v1', 'Eplus-office-mixed-discrete-v1', 'Eplus-office-mixed-continuous-stochastic-v1', 'Eplus-office-mixed-discrete-stochastic-v1', 'Eplus-office-cool-continuous-v1', 'Eplus-office-cool-discrete-v1', 'Eplus-office-cool-continuous-stochastic-v1', 'Eplus-office-cool-discrete-stochastic-v1', 'Eplus-small_office-hot-continuous-v1', 'Eplus-small_office-hot-discrete-v1', 'Eplus-small_office-hot-continuous-stochastic-v1', 'Eplus-small_office-hot-discrete-stochastic-v1', 'Eplus-small_office-mixed-continuous-v1', 'Eplus-small_office-mixed-discrete-v1', 'Eplus-small_office-mixed-continuous-stochastic-v1', 'Eplus-small_office-mixed-discrete-stochastic-v1', 'Eplus-small_office-cool-continuous-v1', 'Eplus-small_office-cool-discrete-v1', 'Eplus-small_office-cool-continuous-stochastic-v1', 'Eplus-small_office-cool-discrete-stochastic-v1', 'Eplus-sitdown_restaurant-hot-continuous-v1', 'Eplus-sitdown_restaurant-hot-discrete-v1', 'Eplus-sitdown_restaurant-hot-continuous-stochastic-v1', 'Eplus-sitdown_restaurant-hot-discrete-stochastic-v1', 'Eplus-sitdown_restaurant-mixed-continuous-v1', 'Eplus-sitdown_restaurant-mixed-discrete-v1', 'Eplus-sitdown_restaurant-mixed-continuous-stochastic-v1', 'Eplus-sitdown_restaurant-mixed-discrete-stochastic-v1', 'Eplus-sitdown_restaurant-cool-continuous-v1', 'Eplus-sitdown_restaurant-cool-discrete-v1', 'Eplus-sitdown_restaurant-cool-continuous-stochastic-v1', 'Eplus-sitdown_restaurant-cool-discrete-stochastic-v1', 'Eplus-warehouse-hot-continuous-v1', 'Eplus-warehouse-hot-discrete-v1', 'Eplus-warehouse-hot-continuous-stochastic-v1', 'Eplus-warehouse-hot-discrete-stochastic-v1', 'Eplus-warehouse-mixed-continuous-v1', 'Eplus-warehouse-mixed-discrete-v1', 'Eplus-warehouse-mixed-continuous-stochastic-v1', 'Eplus-warehouse-mixed-discrete-stochastic-v1', 'Eplus-warehouse-cool-continuous-v1', 'Eplus-warehouse-cool-discrete-v1', 'Eplus-warehouse-cool-continuous-stochastic-v1', 'Eplus-warehouse-cool-discrete-stochastic-v1', 'Eplus-officegrid-hot-continuous-v1', 'Eplus-officegrid-hot-discrete-v1', 'Eplus-officegrid-hot-continuous-stochastic-v1', 'Eplus-officegrid-hot-discrete-stochastic-v1', 'Eplus-officegrid-mixed-continuous-v1', 'Eplus-officegrid-mixed-discrete-v1', 'Eplus-officegrid-mixed-continuous-stochastic-v1', 'Eplus-officegrid-mixed-discrete-stochastic-v1', 'Eplus-officegrid-cool-continuous-v1', 'Eplus-officegrid-cool-discrete-v1', 'Eplus-officegrid-cool-continuous-stochastic-v1', 'Eplus-officegrid-cool-discrete-stochastic-v1', 'Eplus-radiant-hot-discrete-v1', 'Eplus-radiant-hot-discrete-stochastic-v1', 'Eplus-radiant-mixed-discrete-v1', 'Eplus-radiant-mixed-discrete-stochastic-v1', 'Eplus-radiant-cool-discrete-v1', 'Eplus-radiant-cool-discrete-stochastic-v1', 'Eplus-radiant-stockholm-discrete-v1', 'Eplus-radiant-stockholm-discrete-stochastic-v1', 'Eplus-shop-hot-continuous-v1', 'Eplus-shop-hot-discrete-v1', 'Eplus-shop-hot-continuous-stochastic-v1', 'Eplus-shop-hot-discrete-stochastic-v1', 'Eplus-shop-mixed-continuous-v1', 'Eplus-shop-mixed-discrete-v1', 'Eplus-shop-mixed-continuous-stochastic-v1', 'Eplus-shop-mixed-discrete-stochastic-v1', 'Eplus-shop-cool-continuous-v1', 'Eplus-shop-cool-discrete-v1', 'Eplus-shop-cool-continuous-stochastic-v1', 'Eplus-shop-cool-discrete-stochastic-v1']\n"
                    ]
                }
            ],
            "source": [
                "sinergym_environment_ids = get_ids()\n",
                "print(sinergym_environment_ids)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [small_office-cool-continuous-v1]\u001b[0m\n",
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/WORKING/Eplus-env-small_office-cool-continuous-v1-res1]\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n",
                        "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment small_office-cool-continuous-v1 created successfully.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "env = gym.make('Eplus-small_office-cool-continuous-v1')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : New normalized action Space: Box(-1.0, 1.0, (2,), float32)\u001b[0m\n",
                        "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : Wrapper initialized\u001b[0m\n",
                        "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : wrapper initialized.\u001b[0m\n",
                        "\u001b[38;20m[WRAPPER LoggerWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [small_office-cool-continuous-v1] [Episode 1]\u001b[0m\n",
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/WORKING/Eplus-env-small_office-cool-continuous-v1-res1/Eplus-env-sub_run1]\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Weather file CAN_BC_Vancouver.718920_CWEC.epw used.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [CAN_BC_Vancouver.718920_CWEC.epw]\u001b[0m\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/opyplus/weather_data/weather_data.py:493: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
                        "  epw_content = self._headers_to_epw(use_datetimes=use_datetimes) + df.to_csv(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/WORKING/Eplus-env-small_office-cool-continuous-v1-res1/Eplus-env-sub_run1/output]\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/WORKING/Eplus-env-small_office-cool-continuous-v1-res1/Eplus-env-sub_run1/CAN_BC_Vancouver.718920_CWEC.epw', '-d', '/workspaces/sinergym/WORKING/Eplus-env-small_office-cool-continuous-v1-res1/Eplus-env-sub_run1/output', '/workspaces/sinergym/WORKING/Eplus-env-small_office-cool-continuous-v1-res1/Eplus-env-sub_run1/ASHRAE901_OfficeSmall_STD2019_Denver.epJSON']\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
                        "\u001b[38;20m[WRAPPER LoggerWrapper] (INFO) : Creating monitor.csv for current episode (episode 1) if logger is active\u001b[0m\n",
                        "Reward:  -8.619105875673956 {'time_elapsed(hours)': 0.5, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [17.674295, 29.300732], 'timestep': 2, 'reward': -8.619105875673956, 'energy_term': -0.07821680212429456, 'comfort_term': -8.54088907354966, 'reward_weight': 0.5, 'abs_energy_penalty': -1564.336042485891, 'abs_comfort_penalty': -17.08177814709932, 'total_power_demand': 1564.336042485891, 'total_temperature_violation': 17.08177814709932}\n",
                        "Progress: |*--------------------------------------------------------------------------------------------------| 1%\r"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
                        "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reward:  -3169.3853171389546 {'time_elapsed(hours)': 744.25, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.393066, 29.234818], 'timestep': 2977, 'reward': -0.14035207964766916, 'energy_term': -0.14035207964766916, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -2807.0415929533833, 'abs_comfort_penalty': 0, 'total_power_demand': 2807.0415929533833, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -4574.565581298625 {'time_elapsed(hours)': 1416.25, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [15.5621805, 26.678087], 'timestep': 5665, 'reward': -0.13869610265218021, 'energy_term': -0.13869610265218021, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -2773.922053043604, 'abs_comfort_penalty': 0, 'total_power_demand': 2773.922053043604, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -6228.262959516862 {'time_elapsed(hours)': 2160.25, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [16.101477, 25.462656], 'timestep': 8641, 'reward': -0.04146792313221457, 'energy_term': -0.04146792313221457, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -829.3584626442913, 'abs_comfort_penalty': 0, 'total_power_demand': 829.3584626442913, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -7007.825852781727 {'time_elapsed(hours)': 2880.25, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [22.381876, 23.938412], 'timestep': 11521, 'reward': -0.13295579063457166, 'energy_term': -0.1174502743209406, 'comfort_term': -0.015505516313631063, 'reward_weight': 0.5, 'abs_energy_penalty': -2349.005486418812, 'abs_comfort_penalty': -0.031011032627262125, 'total_power_demand': 2349.005486418812, 'total_temperature_violation': 0.031011032627262125}\n",
                        "Progress: |***************************************------------------------------------------------------------| 39%\r"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (terminated \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[1;32m     10\u001b[0m     a \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m---> 11\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m current_month:  \u001b[38;5;66;03m# display results every month\u001b[39;00m\n",
                        "File \u001b[0;32m/workspaces/sinergym/sinergym/utils/wrappers.py:266\u001b[0m, in \u001b[0;36mLoggerWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: Union[\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]\n\u001b[1;32m    257\u001b[0m          ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends action to the environment. Logging new information in monitor.csv.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m        Tuple[np.ndarray, float, bool, Dict[str, Any]]: Observation for next timestep, reward obtained, Whether the episode has ended or not, Whether episode has been truncated or not, and a dictionary with extra information\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# We added some extra values (month,day,hour) manually in env, so we\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# need to delete them.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_wrapped(\u001b[38;5;28mself\u001b[39m, NormalizeObservation):\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;66;03m# Record action and new observation in simulator's csv\u001b[39;00m\n",
                        "File \u001b[0;32m/workspaces/sinergym/sinergym/utils/wrappers.py:86\u001b[0m, in \u001b[0;36mNormalizeObservation.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and normalizes the observation.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Save original obs in class attribute\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munwrapped_observation \u001b[38;5;241m=\u001b[39m deepcopy(obs)\n",
                        "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:591\u001b[0m, in \u001b[0;36mActionWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    590\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs the :attr:`env` :meth:`env.step` using the modified ``action`` from :meth:`self.action`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/workspaces/sinergym/sinergym/envs/eplus_env.py:348\u001b[0m, in \u001b[0;36mEplusEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    346\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_obs \u001b[38;5;241m=\u001b[39m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_info \u001b[38;5;241m=\u001b[39m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
                        "File \u001b[0;32m/usr/lib/python3.10/queue.py:149\u001b[0m, in \u001b[0;36mQueue.put\u001b[0;34m(self, item, block, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m Full\n\u001b[0;32m--> 149\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_put(item)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munfinished_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "env = NormalizeAction(env)\n",
                "env = NormalizeObservation(env)\n",
                "env = LoggerWrapper(env)\n",
                "for i in range(1):\n",
                "    obs, info = env.reset()\n",
                "    rewards = []\n",
                "    truncated = terminated = False\n",
                "    current_month = 0\n",
                "    while not (terminated or truncated):\n",
                "        a = env.action_space.sample()\n",
                "        obs, reward, terminated, truncated, info = env.step(a)\n",
                "        rewards.append(reward)\n",
                "        if info['month'] != current_month:  # display results every month\n",
                "            current_month = info['month']\n",
                "            print('Reward: ', sum(rewards), info)\n",
                "              # Final episode information print\n",
                "    print(\n",
                "        'Episode ',\n",
                "        i,\n",
                "        'Mean reward: ',\n",
                "        np.mean(rewards),\n",
                "        'Cumulative reward: ',\n",
                "        sum(rewards))\n",
                "# Close the environment\n",
                "env.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "vscode": {
            "interpreter": {
                "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
